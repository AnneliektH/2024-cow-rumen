Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 70
Rules claiming more threads will be scaled down.
Provided resources: mem_mb=30000
Job stats:
job            count
-----------  -------
all                1
diamond_all        1
total              2

Select jobs to execute...

[Mon Jun 10 14:42:20 2024]
rule diamond_all:
    input: ../resources/Hugo_metaT.over600.fa
    output: ../results/diamond.Hugo_metaT.over600.all.tsv
    jobid: 1
    reason: Missing output files: ../results/diamond.Hugo_metaT.over600.all.tsv
    wildcards: ident=Hugo_metaT.over600
    threads: 70
    resources: tmpdir=/tmp

Activating conda environment: diamond
[Mon Jun 10 14:42:23 2024]
Error in rule diamond_all:
    jobid: 1
    input: ../resources/Hugo_metaT.over600.fa
    output: ../results/diamond.Hugo_metaT.over600.all.tsv
    conda-env: diamond
    shell:
        
        diamond blastx -q ../resources/Hugo_metaT.over600.fa         --min-orf 600         -e 1e-5 --threads 70         --very-sensitive         --db ALL_DIAMOND -o ../results/diamond.Hugo_metaT.over600.all.tsv
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-06-10T144218.950841.snakemake.log
