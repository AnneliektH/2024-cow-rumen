{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process the DNA assemblies to get viral contigs\n",
    "- concatenate all contigs\n",
    "- remove everything under 10kb\n",
    "- rename\n",
    "- run virsorter2\n",
    "- run iphop\n",
    "- map reads\n",
    "- Run genomad for taxonomy, proteins, proviruses\n",
    "- Run iphop for virus host matching\n",
    "- do we want functional annotation and AMGs? --> run vibrant in that case?\n",
    "\n",
    "All assembled contigs from the xx samples were concatenated into one fasta file. Contigs smaller than 10kb were removed, and contigs were renamed using bbmap (ref) reformat.sh and rename.sh, respectively. Virsorter2 (ref) was then ran on all remaining contigs (n=454,868), using --min-length 10000 and --min-score 0.9. Resulting viral contigs were dereplicated at approximately species level (95% ANI), over 85% of the length of the shorter contig with CD-Hit (ref), using the -c 0.95 and -aS 0.85. Clustering resulted in 44,824 vOTUs that were used for further analysis.\n",
    "Bowtie2 (ref), was used to map reads to vOTUs. A bowtie2 index file was created using the bowtie2-build command, otherwise standard settings. Both metatranscriptomic reads and metagenomic reads were mapped, to get an overview of the respective 'active' viral community and the present viral community. Reads were mapped using the --no-unal and --sensitive settings. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# concatenate all available contigs\n",
    "cat /home/hfm/ER_rumenShotgun/ER_Nanuq/MAG/assembled_reads/NS*/final.contigs.fa > all_DNA_contigs.Hugo.fa\n",
    "\n",
    "# srun \n",
    "srun --account=ctbrowngrp -p bmm -J vs2 -t 0:10:00 -c 1 --mem=50gb --pty bash\n",
    "\n",
    "# rename and remove < 10k\n",
    "mamba activate bbmap\n",
    "reformat.sh in=all_DNA_contigs.Hugo.fa out=all_DNA_contigs.10k.fa minlength=10000 -Xmx50g\n",
    "rename.sh in=all_DNA_contigs.10k.fa out=all_DNA_contigs.10k.rn.fa prefix=ath_rumen_2024_ -Xmx50g\n",
    "\n",
    "# Partition it because virsorter will take forever on 454,868 sequences\n",
    "partition.sh in=../all_DNA_contigs.10k.rn.fa out=out_%.fasta ways=40 -Xmx50g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snakemake virsorter on the subsetted files\n",
    "srun --account=ctbrowngrp -p high2 -J bt2 -t 14:00:00 -c 64 --mem=80gb --pty bash\n",
    "\n",
    "mamba activate branchwater\n",
    "snakemake --use-conda --resources mem_mb=120000 --rerun-triggers mtime \\\n",
    "-c 64 --rerun-incomplete -k -s Snakefile_bowtie -n\n",
    "\n",
    "\n",
    "# snakemake file\n",
    "FASTA, = glob_wildcards('../resources/split_DNA_contigs/{fasta}.fasta')\n",
    "\n",
    "rule all:\n",
    "    input:\n",
    "        expand(\"../results/virsorter2/DNA/check/{fasta}.done\", fasta=FASTA),\n",
    "\n",
    "rule virsorter2:\n",
    "    input:\n",
    "        fasta = '../resources/split_DNA_contigs/{fasta}.fasta',\n",
    "    output:\n",
    "        check='../results/virsorter2/DNA/check/{fasta}.done',\n",
    "    conda: \n",
    "        \"virsorter2\"\n",
    "    threads: 16\n",
    "    shell:\n",
    "        \"\"\"\n",
    "        virsorter run all -w ../results/virsorter2/DNA/{wildcards.fasta} \\\n",
    "        -i {input.fasta} -d /group/jbemersogrp/databases/virsorter/ \\\n",
    "        --min-length 10000 -j {threads} --min-score 0.9\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resulted in 58,188 viral contigs\n",
    "# Now concatenate and drep at 95\n",
    "\n",
    "# srun \n",
    "srun --account=ctbrowngrp -p bmm -J vs2 -t 0:10:00 -c 1 --mem=50gb --pty bash\n",
    "\n",
    "# rename again bc of stupid ||\n",
    "mamba activate bbmap\n",
    "rename.sh in=viral_contigs.fa out=viral_contigs.rn.fa prefix=ath_rumvir_24_ -Xmx50g\n",
    "\n",
    "# split contigs for drep\n",
    "mkdir contigs\n",
    "cd ./contigs\n",
    "awk '/^>/ {OUT=substr($0,2) \".fa\"}; OUT {print >OUT}' ../viral_contigs.95.cluster.fa \n",
    "\n",
    "srun --account=ctbrowngrp -p bmh -J drep -t 10:00:00 -c 24 --mem=100gb --pty bash\n",
    "mamba activate drep\n",
    "\n",
    "# Run dRep at 95% ANI over 85% of length of longest contigs\n",
    "dRep dereplicate ./drep --S_algorithm ANImf --ignoreGenomeQuality -l 10000 -sa 0.95 -nc 0.85 -p 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now cdhit to deduplicate, drep being shitty (result in 44824 vir clusters)\n",
    "srun --account=ctbrowngrp -p bmm -J cdhit -t 1:00:00 -c 40 --mem=70gb --pty bash\n",
    "\n",
    "mamba activate cdhit\n",
    "cd-hit-est -i viral_contigs.rn.fa \\\n",
    "-o viral_contigs.95.cluster.fa -d 0 \\\n",
    "-c 0.95 -aS 0.85 -M 95000 -T 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bowtie2 build the db\n",
    "mamba activate bowtie2\n",
    "bowtie2-build ../../drep/DNA/viral_contigs.95.cluster.fa ./viral_contigs.95.cluster -p 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for the RVD\n",
    "srun --account=ctbrowngrp -p bmm -J bowtie2 -t 8:00:00 -c 40 --mem=70gb --pty bash\n",
    "mamba activate bowtie2\n",
    "bowtie2-build ../../resources/RVD/RVD_rn.fa ./RVD -p 40 --large-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVERAGE TABLE\n",
    "# Use coverM to create a coverage table for vOTUs\n",
    "srun --account=ctbrowngrp -p bmm -J coverm -t 1:00:00 -c 1 --mem=30gb --pty bash\n",
    "\n",
    "mamba activate coverm\n",
    "\n",
    "# make a coverage table, where the min amount of the contig that has to be covered is 75%\n",
    "coverm contig -m mean --min-covered-fraction 0.75 \\\n",
    "-b *.bam > ../../240923_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNA reads:\n",
    "/home/hfm/ER_rumenShotgun/ER_Nanuq/TRIMMED/*R1_trim.fastq.gz\n",
    "\n",
    "# metaT reads\n",
    "/home/hfm/Rumen_Microbiome_Genomics/1_Sequences_Guanhui/TRIMMED/18048XR-81-24_S11_L003_R2_001_trim.fixed.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For normalization of the coveragbin.12741e table, we need the number of reads per sample\n",
    "mamba activate seqkit\n",
    "seqkit stats /home/hfm/ER_rumenShotgun/ER_Nanuq/TRIMMED/*R1_trim.fastq.gz > num_reads.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENOMAD\n",
    "# srun it, needs quite some mem\n",
    "srun --account=ctbrowngrp -p med2 -J genomad -t 12:00:00 -c 36 --mem=100gb --pty bash\n",
    "\n",
    "# end to end for everything, need to annotate for classification\n",
    "# Use for taxonomy of DNA phage\n",
    "\n",
    "mamba activate genomad\n",
    "genomad end-to-end \\\n",
    "../drep/DNA/viral_contigs.95.cluster.fa \\\n",
    "./DNA/ ./genomad_db \\\n",
    "--threads 36 --enable-score-calibration \\\n",
    "--splits 20 --cleanup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iphop (maybe, also try diff method for virus-host linkages)\n",
    "# Wait with running iphop until the MAGs are here?\n",
    "ln -s /group/jbemersogrp/databases/iphop . \n",
    "\n",
    "# run it\n",
    "srun --account=ctbrowngrp -p med2 -J iphop -t 24:00:00 -c 60 --mem=70gb --pty bash\n",
    "\n",
    "mamba activate iphop_env\n",
    "iphop predict -f viral_contigs.95.cluster.fa \\\n",
    "-o ./ -d ./iphop/latest/Aug_2023_pub_rw -t 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run vibrant for AMG purposes?\n",
    "# not needed if running DRAM-v\n",
    "srun --account=ctbrowngrp -p med2 -J vibrant -t 24:00:00 -c 40 --mem=70gb --pty bash\n",
    "\n",
    "mamba activate vibrant\n",
    "VIBRANT_run.py \\\n",
    "-i viral_contigs.95.cluster.fa -folder ../../VIBRANT \\\n",
    "-t 40 -d /group/jbemersogrp/databases/vibrant/databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRAM-v for AMGs as well --> do need dramV\n",
    "# First need to prepare the virsorter output\n",
    "srun --account=ctbrowngrp -p med2 -J VS2 -t 14:00:00 -c 80 --mem=60gb --pty bash\n",
    "\n",
    "virsorter run --prep-for-dramv -w ../../DRAMv \\\n",
    "-i viral_contigs.95.cluster.fa -j 48 all \\\n",
    "-d /group/jbemersogrp/databases/virsorter/ \n",
    "\n",
    "\n",
    "# Is 64 hours with 80 threads not enough? :(\n",
    "srun --account=ctbrowngrp -p med2 -J DRAMv -t 24:00:00 -c 40 --mem=60gb --pty bash\n",
    "srun --account=ctbrowngrp -p med2 -J DRAMv -t 120:00:00 -c 80 --mem=80gb --pty bash\n",
    "\n",
    "# then run dramv\n",
    "mamba activate DRAM\n",
    "\n",
    "/group/jbemersogrp/databases/dram/\n",
    "\n",
    "DRAM-v.py annotate -i VS2/for-dramv/final-viral-combined-for-dramv.fa \\\n",
    "-v VS2/for-dramv/viral-affi-contigs-for-dramv.tab --threads 80 \\\n",
    "-o DRAMv --skip_trnascan\n",
    "\n",
    "# I dont need tRNAs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TerL tree\n",
    "- Get all TerL sequences from VIBRANT predictions (K06909) (seqtk)\n",
    "- Get all TerL sequences from Refseq\n",
    "- Cluster sequences at 95% AAI (CD-hit)\n",
    "- remove everything < 100 AA\n",
    "- align protein sequences (MAFFT)\n",
    "- TrimAL\n",
    "- Prottest\n",
    "- IQ tree or fasttree\n",
    "\n",
    "\n",
    "### Numbers:\n",
    "Refseq: 4711\n",
    "own: 5105\n",
    "RVD: 10917\n",
    "After dereplicating:\n",
    "Refseq: 1830\n",
    "own: 2975\n",
    "RVD: 6968\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to folder\n",
    "cd results/TerL_tree/\n",
    "\n",
    "# link refseq seqs to folder\n",
    "ln -s ../../resources/TerL_refseq.fasta .\n",
    "\n",
    "# rm header spaces\n",
    "cut -d ' ' -f1 prodigal_w_spaces.fa > rumvir_vibrant.faa\n",
    "\n",
    "# Subset all protein predictions to only protein predictions that are TerL from own seqs\n",
    "seqtk subseq rumvir_vibrant.faa terl.vibrant.txt > TerL.vibrant.faa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster using CD-hit\n",
    "srun --account=ctbrowngrp -p med2 -J cdhit -t 4:00:00 -c 15 --mem=50gb --pty bash\n",
    "mamba activate cdhit\n",
    "\n",
    "# own \n",
    "mamba activate cdhit\n",
    "cd-hit -i TerL.vibrant.faa -o ../TerL.vibrant.95.cluster.faa \\\n",
    "-c 0.95 -T 15 -d 0\n",
    "\n",
    "# refseq\n",
    "cd-hit -i TerL_refseq.fasta \\\n",
    "-o ../TerL.refseq.95.cluster.fa -d 0 \\\n",
    "-c 0.95 -T 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAFFT seems to perform better\n",
    "srun --account=ctbrowngrp -p med2 -J ginsi -t 4:00:00 -c 25 --mem=120gb --pty bash\n",
    "mamba activate mafft\n",
    "\n",
    "# use very fast method\n",
    "mafft --retree 1 --maxiterate 0 TerL.rs.own.faa > TerL.rs.own.mafft\n",
    "\n",
    "# also for the refseq, own, rvd\n",
    "mafft --retree 1 --maxiterate 0 TerL.rs.own.rvd.faa > TerL.rs.own.rvd.mafft\n",
    "\n",
    "# sliced out positions with >50% gaps, using trimal\n",
    "# https://www.nature.com/articles/s41467-023-41075-2#Sec10\n",
    "mamba activate trimal\n",
    "trimal -in TerL.rs.own.mafft -gt 0.5 -out TerL.rs.own.trimal.faa\n",
    "trimal -in TerL.rs.own.rvd.mafft -gt 0.5 -out TerL.rs.own.rvd.trimal.faa\n",
    "\n",
    "# FastTree for building trees\n",
    "mamba activate fasttree\n",
    "FastTree < TerL.rs.own.trimal.faa > TerL.rs.own.mafft.tree -wag -mlacc 2 -slownni -log mafft.tree.log\n",
    "FastTree < TerL.rs.own.rvd.trimal.faa > TerL.rs.own.rvd.mafft.tree -wag -mlacc 2 -slownni -log mafft.tree.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the TerL sequences\n",
    "cat RVD_*/RVD*.faa > RVD_all.faa\n",
    "\n",
    "# grep terL (n=10917)\n",
    "grep -i -e 'terminase' RVD_all.faa > TerL.RVD.headers.txt\n",
    "\n",
    "\n",
    "# rm header spaces \n",
    "cut -d ' ' -f1 RVD_all.faa > RVD_all.ns.faa\n",
    "\n",
    "# Subset all protein predictions to only protein predictions that are TerL from own seqs\n",
    "seqtk subseq RVD_all.ns.faa TerL.rvd.txt > TerL.RVD.faa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derep using cdhit\n",
    "srun --account=ctbrowngrp -p med2 -J ginsi -t 1:00:00 -c 15 --mem=120gb --pty bash\n",
    "\n",
    "# own \n",
    "mamba activate cdhit\n",
    "cd-hit -i TerL.RVD.faa -o TerL.RVD.95cluster.faa \\\n",
    "-c 0.95 -T 15 -d 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Align with clustalo\n",
    "# mamba activate clustalo\n",
    "# clustalo -i TerL.vibrant.refseq.faa \\\n",
    "# --auto -t Protein --threads=15 \\\n",
    "# -o TerL.refseq.alignment\n",
    "\n",
    "\n",
    "# # also try ginsi\n",
    "# mafft --globalpair --maxiterate 1000 \\\n",
    "# --thread 25 TerL.vibrant.refseq.faa > TerL.refseq.mafft.ginsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping to RVD also gained 40.000 vOTUs. Now drep with own vOTUs\n",
    "# 44824 own vOTUs, 49066 RVD\n",
    "filterbyname.sh in=../DNA/viral_contigs.95.cluster.fa out=own.fa names=contigs.txt include=t\n",
    "filterbyname.sh in=../../../resources/RVD/RVD_rn.fa \\\n",
    "out=RVD.fa names=contigs.txt include=t\n",
    "\n",
    "\n",
    "# now cdhit to deduplicate, drep being shitty (result in 44824 vir clusters)\n",
    "srun --account=ctbrowngrp -p bmm -J cdhit -t 4:00:00 -c 40 --mem=90gb --pty bash\n",
    "\n",
    "# sort by length first\n",
    "sortbyname.sh in=ownRVD.fa out=ownRVD.sortlen.fa descending\n",
    "\n",
    "# result is 91,461 vOTUs\n",
    "mamba activate cdhit\n",
    "cd-hit-est -i ownRVD.sortlen.fa \\\n",
    "-o ownRVD.95.cluster.fa -d 0 \\\n",
    "-c 0.95 -aS 0.85 -M 90000 -T 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map reads to this dataset?\n",
    "# Probably should remove the RVD mapping only in that case. \n",
    "# bowtie2 build the db\n",
    "srun --account=ctbrowngrp -p med2 -J bt2 -t 10:00:00 -c 40 --mem=80gb --pty bash\n",
    "\n",
    "mamba activate bowtie2\n",
    "bowtie2-build ../drep/RVD_own/ownRVD.95.cluster.fa \\\n",
    "./ownRVD.95.cluster.bowtie -p 40 --large-index\n",
    "\n",
    "mamba activate branchwater\n",
    "snakemake --use-conda --resources mem_mb=80000 --rerun-triggers mtime \\\n",
    "-c 40 --rerun-incomplete -k -s Snakefile_bowtie -n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
